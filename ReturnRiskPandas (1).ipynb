{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Propensity using ICP4D and Watson Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this notebook to create a machine learning model to predict customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Import the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import the data in the AggregatedOrderData.csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'botocore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q5/y3vfc1bj0c31_1ghl5dq0_040000gn/T/ipykernel_19736/355275372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mibm_boto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'botocore'"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "## Add credentials here!!!!\n",
    "\n",
    "body = client_8aa33f240a004f5683941ade3d2b1ba6.get_object(Bucket='dsworkshop-donotdelete-pr-7bxfdbxyx7dtjo',Key='AggregatedOrderData.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df = pd.read_csv(body)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 We will first fill all NA(s) and empty values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Next we will see if we have any columns of dtype=object. These will then be converted to category codes in order to be fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qual = list( df.loc[:,df.dtypes == 'object'].columns.values )\n",
    "# for col in qual:\n",
    "#      df[col] = df[col].astype('category')\n",
    "# quant = list( df.loc[:,df.dtypes != 'category'].columns.values )\n",
    "# print(qual,quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats = list( df.loc[:,df.dtypes == 'category'].columns.values)\n",
    "# categories={}\n",
    "# for col in cats:\n",
    "#     categories[col]= dict(enumerate(df[col].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Next, we find out how many orders were returned and how many were not returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RETURN_FLAG\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can see that there are ~24K orders that have been returned and ~128K orders that have not been returned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Let's split our data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=(df.drop([\"RETURN_FLAG\"], axis=1))\n",
    "y=df['RETURN_FLAG']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3., random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Install Custom Modules for the Pipeline Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Let us now install the custom transformation library that we had uploaded to the project - CustTrans-0.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "\n",
    "\n",
    "## Add credentials here!!!!\n",
    "\n",
    "\n",
    "def downloadFileCos(bucketDetails): \n",
    "    cos = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=bucketDetails['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=bucketDetails['IAM_SERVICE_ID'],\n",
    "    ibm_auth_endpoint=bucketDetails['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=bucketDetails['ENDPOINT'])\n",
    "    res=cos.download_file(Bucket=bucketDetails['BUCKET'],Key=\"CustTrans-0.2.zip\",Filename=\"CustTrans-0.2.zip\")\n",
    "    print(\"CustomTransformer file downloaded\")\n",
    "\n",
    "downloadFileCos(credentials_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade CustTrans-0.2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Next, we install the sklearn-pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Now, let us create the custom pipeline transformer which essentially is our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomTransformer.CustTrans import TypeSelector,StringIndexer,ConvToCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "\n",
    "transformer = Pipeline([\n",
    "   ('features', FeatureUnion(n_jobs=1, transformer_list=[\n",
    "       # Part 1\n",
    "       ('boolean', Pipeline([\n",
    "           ('selector', TypeSelector('bool')),\n",
    "       ])),  # booleans close\n",
    "       ('numericals', Pipeline([\n",
    "           ('selector', TypeSelector(np.number)),\n",
    "           ('scaler', StandardScaler()),\n",
    "       ])),\n",
    "       # Part 2\n",
    "       ('categoricals', Pipeline([\n",
    "           ('convertor', ConvToCategorical()),\n",
    "           ('selector', TypeSelector('category')),\n",
    "           ('labeler', StringIndexer()),\n",
    "           ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "       ]))\n",
    "       # categoricals close\n",
    "   ])),  # features close\n",
    "   ('clf' , RandomForestClassifier(n_estimators=30,criterion=\"entropy\")),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Let's now pass the input data through the transformer(fit), also known as training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "transformer.fit(X_train, y_train)\n",
    "print(\"Time for model training\",timeit.default_timer() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Once training is complete, we can evaluate the accuracy of the model using the hold-out test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores= transformer.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, scores)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Save and deploy the model to WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create a WML API client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = \"## Add API Key here!!!!\"\n",
    "wml_credentials = {\n",
    "                   \"url\": \"https://eu-gb.ml.cloud.ibm.com\",\n",
    "                   \"apikey\":apikey\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following cell to perform any clean up of previously created models, deployments and spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.spaces.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if any spaces already exist\n",
    "# client.spaces.list()\n",
    "\n",
    "# set the default space before moving ahead\n",
    "# client.set.default_space('<GUID of the space>')\n",
    "\n",
    "# see if any stored models exist\n",
    "# client.repository.list_models()\n",
    "# client.repository.delete('<GUID of model to delete>')\n",
    "\n",
    "# see if any deployments exist\n",
    "# client.deployments.list()\n",
    "# client.deployments.delete('<GUID of deployment to delete>')\n",
    "\n",
    "# once the deployments and models are deleted, the space can be deleted\n",
    "# client.spaces.delete('<GUID of the space>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a deployment space and set it as the default space to be used for deployments. If you would rather use an existing space (that was previously created), skip the code in the cell below and directly use the next cell to set the default space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code to create a new deployment space.\n",
    "# space_details = client.spaces.store(meta_props={client.spaces.ConfigurationMetaNames.NAME: \"ReturnPropensity_Space\"})\n",
    "# space_id = client.spaces.get_uid(space_details)\n",
    "# print(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default space - if you have a previously created space that you'd like to use, \n",
    "# use that space's id instead of `space_id`. For eg. client.set.default_space('<GUID of the space>')\n",
    "client.set.default_space(\"## Add SPACE ID here!!!!\")\n",
    "print(client.deployments.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Before we deploy the model, let's create a custom python runtime with our custom transformer library installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Create a package extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_prop_pkg_extn = {\n",
    "    client.package_extensions.ConfigurationMetaNames.NAME: \"CustomTransformers_v0.1\",\n",
    "    client.package_extensions.ConfigurationMetaNames.DESCRIPTION: \"Pkg extension for custom lib\",\n",
    "    client.package_extensions.ConfigurationMetaNames.TYPE: \"pip_zip\"\n",
    "}\n",
    "\n",
    "pkg_extn_details = client.package_extensions.store(meta_props=meta_prop_pkg_extn, file_path=\"CustTrans-0.2.zip\")\n",
    "pkg_extn_uid = client.package_extensions.get_uid(pkg_extn_details)\n",
    "pkg_extn_url = client.package_extensions.get_href(pkg_extn_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = client.package_extensions.get_details(pkg_extn_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Create software specification and add custom library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.software_specifications.ConfigurationMetaNames.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sw_spec_uid = client.software_specifications.get_uid_by_name(\"default_py3.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_prop_sw_spec = {\n",
    "    client.software_specifications.ConfigurationMetaNames.NAME: \"CustomTransformers_v0.1\",\n",
    "    client.software_specifications.ConfigurationMetaNames.DESCRIPTION: \"Software specification for CustomTransformers_v0.1\",\n",
    "    client.software_specifications.ConfigurationMetaNames.BASE_SOFTWARE_SPECIFICATION: {\"guid\": base_sw_spec_uid}\n",
    "}\n",
    "\n",
    "sw_spec_details = client.software_specifications.store(meta_props=meta_prop_sw_spec)\n",
    "sw_spec_uid = client.software_specifications.get_uid(sw_spec_details)\n",
    "\n",
    "\n",
    "client.software_specifications.add_package_extension(sw_spec_uid, pkg_extn_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Now, let us store our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {\n",
    "    client.repository.ModelMetaNames.NAME: \"ReturnRiskPandas_v0.1\",\n",
    "    client.repository.ModelMetaNames.TYPE: 'scikit-learn_0.23',\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sw_spec_uid\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = client.repository.store_model(model=transformer, meta_props=model_props,training_data=X_train, training_target=y_train)\n",
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Finally, let's deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaProps = {\n",
    "client.deployments.ConfigurationMetaNames.NAME: \"ReturnRiskPandas_CustomTransformers_v0.1\",\n",
    "client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_deployment = client.deployments.create(published_model_uid, metaProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Obtain the deployment_id and deployment_href for the model.\n",
    "\n",
    "The deployment_id is required to score the model using the client.deployments.score() methos in the WML API Client.\n",
    "The deployment_href can be used to generate the URL to be used to score the model via a cURL command. The scoring_url can be generated as `\"<URL for your IBM Cloud Pak for Data cluster>\" + <deployment_href>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_uid = client.deployments.get_uid(created_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_href(created_deployment)\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Score the model using a sample payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_payload={client.deployments.ScoringMetaNames.INPUT_DATA: [{\"fields\":[\"BASKET_SIZE\",\"EXTN_COMPOSITION\",\"CARRIER_SERVICE_CODE_OL\",\"CATEGORY\",\"COUNTRY_OF_ORIGIN_OI\",\"DAY_OF_MONTH\",\"DAY_OF_WEEK\",\"DAY_OF_YEAR\",\"EXTN_BRAND\",\"EXTN_DISCOUNT_ID\",\"EXTN_IS_GIFT\",\"EXTN_IS_PREORDER\",\"EXTN_SHIP_TO_CITY\",\"EXTN_SHIP_TO_COUNTRY\",\"EXTN_SEASON\",\"LIST_PRICE\",\"MONTH_OF_YEAR\",\"OTHER_CHARGES\",\"OTHER_CHARGES_OL\",\"REQ_DELIVERY_DATE\",\"TOTAL_AMOUNT_USD\",\"WEEKEND\",\"ZIP_CODE\",\"MTS_CTS\",\"HOUR_OF_DAY\",\"LOCKID\"],\"values\":[[3, '91% Nylon, 9% Elastercell', 'STANDARD', 'Bikini', 'US', 18, 'Saturday', 322, 'XYZAI', 'None', 'N', 'N', 'Los Angeles', 'US', 'FW17', 75, 11, 0.0, 0.0, 0, 165.35, 1, 'Zipcode_401', 24, 19, 277]]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = client.deployments.score(deployment_uid, scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first field - prediction - indicates the model's prediction of whether the items indicated by the sample payload will be returned (value of 0) or not (value of 1). The second field - probability - has 2 numeric values. The first corresponds to the probability of a prediction value of 0 and the second corresponds to the probability of the prediction value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
